\chapter{INTRODUÇÃO}
\thispagestyle{empty}

As redes neurais artificiais (do inglês, \textit{Artificial Neural Network} - ANN) são utilizadas em diversas aplicações para resolução de problemas, como visão computacional, reconhecimento de fala e de padrões \cite{applications}. Para que esses algoritmos alcancem um resultado satisfatório, um dos principais requisitos é realizar o treinamento da rede com o uso de um conjunto de dados que representem bem os casos do mundo real, com o objetivo de garantir a generalização do aprendizado para dados não vistos.

Apesar do grande sucesso das redes neurais, elas podem ser classificadas como um algoritmo caixa preta, sendo, basicamente, o funcionamento computado para a aquisição da resposta da ANN, dado um conjunto de entradas, não humanamente interpretável. Essa falta de explicações para o seu comportamento pode prejudicar sistemas críticos que permitem apenas uma pequena margem para falhas, como aplicações médicas e financeiras. Além disso, com o avanço de leis de proteção de dados observável em diversas regiões do mundo, como na União Europeia \cite{lei_EU}, está ficando cada vez mais necessário disponibilizar uma explicação do que está sendo realizado com os dados dos seus respectivos donos. 

A existência de exemplos adversariais é outro motivo para a necessidade do desenvolvimento de abordagens que computam explicações para algoritmos de aprendizagem de máquina, incluindo redes neurais. De acordo com o trabalho de \citeonline{adversarial_examples}, exemplos adversariais são instâncias classificadas erroneamente por um modelo de aprendizagem de máquina que são minimamente diferentes de uma outra instância classificada corretamente, demonstrando a fraqueza desses algoritmos para pequenas pertubações nos dados de entrada que, muitas vezes, poderiam terem sido adquiridas na própria etapa de aquisição do conjunto de dados. 

Os métodos heurísticos são as principais abordagens utilizadas com o intuito de disponibilizar explicações para as saídas de qualquer modelo de aprendizagem de máquina atualmente, pelo fato de serem considerados algoritmos \textit{model-agnostic}, como o LIME \cite{LIME} e ANCHOR \cite{ANCHOR}. Porém, de acordo com o trabalho de \citeonline{Ignatiev_why}, como eles exploram o espaço da instância localmente, esses algoritmos não acarretam em respostas que possuam garantias formais, resultando em explicações locais que podem ser otimistas (quando existem instâncias no espaço de instâncias que a explicação computada falha) ou pessimistas (quando alguma \textit{feature} pertencente à explicação computada é irrelevante e pode ser descartada).

Assim, abordagens não heurísticas para a computação dessas explicações tem sido abordadas em alguns trabalhos recentes. O artigo de \citeonline{Ignatiev_abduction} apresenta  um algoritmo \textit{model-agnostic}, assim como os métodos heurísticos, porém a computação das explicações mínimas geradas carregam uma garantia formal, pois a sua proposta é baseada em lógica utilizando o raciocínio abdutivo. A abordagem basicamente codifica um modelo $M$ de aprendizagem de máquina como um conjunto de restrições lineares $F$ em alguma teoria, a partir de um verificador de rede neural, que no caso é usado a modelagem de um problema de Programação Linear Inteira Mista (do inglês, \textit{Mixed Integer Linear Programming} - MILP) proposto por \citeonline{milp_01}, então, dado uma instância $C$ associado com a predição $E$ tal que $C \wedge F \models E$ (equivalente à $C \models (F \rightarrow E)$), é computada a explicação mínima $C'$ (dado $C$) que é implicante principal de  $F \rightarrow E$.

Ressalta-se, como um dos principais problemas da proposta de \citeonline{Ignatiev_abduction}, a escalabilidade do algoritmo, podendo demorar um tempo de execução impraticável para ser colocado em produção quando se deseja obter explicações de redes neurais com várias camadas possuindo muitos neurônios. No artigo é apontado que os testes foram realizados apenas com redes de uma camada oculta com 10, 15 ou 20 neurônios. Além disso, os autores não utilizaram outras possíveis modelagens da rede para tentar resolver o problema da escalabilidade. Porém, é possível encontrar outras codificações de redes neurais como restrições MILP que possuem, em relação ao problema de verificar a robustez de uma ANN para exemplos adversariais, maior eficiência na literatura. Por exemplo, a abordagem apresentada no trabalho de \citeonline{milp_top}, que aponta, nos seus resultados, a sua superioridade em relação à codificação usada por \citeonline{milp_01} e \citeonline{reluplex} (que era o antigo estado da arte). 

Além disso, é possível utilizar esse algoritmo proposto por \citeonline{Ignatiev_abduction} para validar, reparar (caso sejam otimistas) e refinar (caso sejam pessimistas) as explicações de modelos de aprendizagem de máquina computadas por métodos heurísticos, como evidenciado em \citeonline{Ignatiev_why}. Porém, os autores realizaram essas operações apenas em modelos de \textit{boosted trees}, e também haveria o problema da escalabilidade ao utilizar redes neurais artificiais com várias camadas, pelo fato de ser o mesmo método. 

Fundamentado na importância de disponibilizar explicações decorrentes de algoritmos que carregam garantias formais, este trabalho possui o objetivo de melhorar, em termos de escalabilidade, a abordagem do artigo de \citeonline{Ignatiev_abduction} a partir do uso da codificação das ANNs proposta por \citeonline{milp_top}, utilizando o raciocínio abdutivo para a aquisição de explicações mínimas para redes neurais artificiais. Além disso, este trabalho também almeja utilizar essa abordagem implementada para a validação, reparação e refinamento de explicações heurísticas para esses modelos.


Assim, os objetivos específicos do trabalho proposto seguem a listagem abaixo:
\begin{enumerate}[a)]
    \item Melhorar, em termos de escalabilidade, a abordagem original de \citeonline{Ignatiev_abduction} substituindo a codificação das redes neurais como restrições MILP utilizada pela proposta em \citeonline{milp_top};
    \item Comparar o método original com a versão implementada com o uso de redes neurais artificiais com diferentes quantidades de camadas ocultas e de neurônios;
    \item Validar, reparar e refinar explicações heurísticas computadas para redes neurais artificiais com diferentes quantidades de camadas ocultas e de neurônios com o uso da versão implementada.
\end{enumerate}

Dessa forma, a hipótese deste trabalho é que ao trocar a codificação de redes neurais artificiais como restrições MILP de \citeonline{milp_01} pela proposta em \citeonline{milp_top}, espera-se uma melhora na escalabilidade do algoritmo de \citeonline{Ignatiev_abduction} para a computação de explicações mínimas para ANNs com o uso do raciocínio abdutivo. Essa melhora também possibilita a validação, reparação e refinamento de explicações heurísticas de redes neurais mais profundas e com mais neurônios, pelo fato dessas três operações propostas por \citeonline{Ignatiev_why} utilizarem esse algoritmo como base. 

Essa expectativa na melhora da escalabilidade do algoritmo ao trocar os codificadores é justificada nos resultados das experimentações realizadas por \citeonline{milp_top}. Nesse trabalho é apontado a superioridade da sua abordagem, em termos de tempo de resolução de um problema MILP, em relação ao antigo estado da arte \cite{reluplex}, e por consequência também à abordagem de \citeonline{milp_01}, para o problema de verificação de robustez de ANNs para exemplos adversariais. Logo, apesar de ser tratado outro problema neste trabalho (computação de explicações para redes neurais), provavelmente a codificação de \citeonline{milp_top} também pode oferecer esse ganho para o algoritmo proposto, aumentando a sua escalabilidade.

\section{Resumo dos artigos selecionados}

O trabalho de \citeonline{Ignatiev_abduction} apresenta um algoritmo \textit{model-agnostic}, significando que funciona em qualquer modelo desde que ele possa ser representado por um sistema de raciocínio de restrição e que consultas de implicação possam ser decididas por um oráculo. Essa abordagem utiliza o raciocínio abdutivo para computar explicações mínimas para modelos de aprendizagem de máquina com garantias formais, fornecendo explicações de cardinalidade mínima ou subconjunto mínima. A abordagem basicamente codifica um modelo $M$ de aprendizagem de máquina como um conjunto de restrições lineares $F$ em alguma teoria, a partir de um algoritmo 0-1 MILP \cite{milp_01}, então, dado uma instância $C$ associado com a predição $E$ tal que $C \wedge F \models E$ (equivalente à $C \models (F \rightarrow E)$), é computada a explicação mínima $C'$ (dado $C$) que é implicante principal de  $F \rightarrow E$. 

O artigo de \citeonline{milp_01} propõe um algoritmo que realiza a codificação de uma rede neural profunda como um 0-1 MILP que usa restrições de indicação para evitar o uso da notação de \textit{Big-M}, utilizando variáveis de ativação binárias para impor as implicações lógicas. Foi realizado a modelagem de aplicações que usavam redes com ReLUs e \textit{max/average pooling}. Esse modelo codificado em restrições lineares não é suscetível à treinamento, pois ele se torna bilinear nessa configuração. Foi realizado experimentos do algoritmo em dois problemas de aprendizagem de máquina: visualização de características e aprendizagem de máquina adversário.

O trabalho de \citeonline{milp_top} implementa um algoritmo MILP que codifica as partes lineares (camadas que usam transformações lineares ou funções que possuam partes lineares, como ReLU e \textit{max pooling}) de uma rede neural como restrições lineares, minimizando o número de variáveis binárias presentes no problema MILP e melhorando o condicionamento numérico. Seja a função de ativação ReLU $y = max(x, 0)$ e $l \leq x \leq u$, para a sua formulação é considerado que há 3 fases: a unidade está estavelmente inativa (quando $u \leq 0$), estavelmente ativa (quando $l \geq 0$) e instável (caso contrário). Para unidades instáveis é utilizado o conjunto de restrições lineares e inteiras na Equação \ref{eq:milp_top}, com a introdução de uma variável de indicação de decisão $a = 1_{x \geq 0}$.

\begin{equation}
    (y \leq x - l(1- a)) \wedge (y \geq x) \wedge (y \leq u*a) \wedge (y \geq 0) \wedge (a \in \{0, 1\})
    \label{eq:milp_top}
\end{equation}

Para indicar se uma unidade ReLU é instável ou não, é preciso definir os seus limites de entrada o mais achatado possível, porém ainda sendo válidos. Para isso, são utilizados dois procedimentos: Intervalo Aritmético e Programação Linear. Essa abordagem foi realizada na aplicação de exemplos adversariais sendo de duas a três vezes de ordem de magnitude mais rápida que o estado da arte, permitindo um aumento significativo do tamanho das redes neurais codificadas.

O artigo de \citeonline{Ignatiev_why} descreve os experimentos realizados que questionam as explicações de modelos de aprendizagem de máquina dadas por métodos heurísticos, que computam uma explicação explorando localmente o espaço da instância. Para realização desses experimentos é utilizado abordagens baseadas em lógica com o cálculo de implicantes principais por meio do raciocínio abdutivo, realizando os testes em \textit{boosted trees}. Os algoritmos desenvolvidos possuem os objetivos de acessar a qualidade das explicações locais, reparar as explicações locais que são otimistas (quando existem instâncias no espaço de instâncias que a explicação computada falha) e refinar as explicações locais que são pessimistas (quando alguma literal pertencente à explicação computada é irrelevante e pode ser descartada).

O trabalho de \citeonline{reluplex} implementa o algoritmo Reluplex, um SMT \textit{solver} para a teoria da aritmética linear real que tem o objetivo de verificar redes neurais profundas utilizando uma técnica baseada no Simplex, porém adaptada para lidar com a função de ativação não-convexa ReLU sem simplificações no seu funcionamento original, apenas permitindo que suas entradas e saídas sejam temporariamente inconsistentes e corrigidas conforme a execução do algoritmo. O Reluplex foi avaliado em 45 redes neurais profundas desenvolvidas como um protótipo inicial do sistema anti-colisão de última geração para aeronaves não tripuladas ACAS Xu. 

Este trabalho é fundamentado no artigo de \citeonline{Ignatiev_abduction}, que utilizada um 0-1 MILP \cite{milp_01} para a codificação da rede neural como um conjunto de restrições lineares em uma teoria, então são computadas explicações para os seus resultados com o uso do raciocínio abdutivo. A necessidade de tais explicações computadas carregando uma garantia formal é evidenciada em \citeonline{Ignatiev_why}. Um dos objetivos iniciais é comparar os possíveis resultados desse algoritmo utilizando diferentes MILPs e estratégias de codificação (verificação) das redes neurais, como os implementados em \citeonline{milp_top} e \citeonline{reluplex}.